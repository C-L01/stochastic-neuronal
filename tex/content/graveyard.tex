%%% Old MP-solution construction that fails because generator maps to B(R^N) instead of C_0(R^N)

\begin{definition}
  An operator \(L\) on (a subset of) \(C_0(\potspace^N)\) is said to satisfy the \textit{positive maximum principle} if for all \(\varphi \in D(L)\), \(\hat{\bm{x}} \in \potspace^N\) with \(\sup_{\bm{x}\in\potspace^N} \varphi(\bm{x}) = \varphi(\hat{\bm{x}}) \geq 0\) we have \(L \varphi(\hat{\bm{x}}) \leq 0\).
\end{definition}

\begin{lemma}\label{lem:pos-max}
  For any \(\lambda > 0\), \(N \in \bN\), the linear operator \(L^{\lambda, N}\) satisfies the positive maximum principle.
\end{lemma}
\begin{proof}
  Because \(D_L \subset C^1(\potspace^N)\), \(\varphi(\hat{\bm{x}}) = \sup_{\bm{x}\in\potspace^N} \varphi(\bm{x})\) implies that \(\partial_{x^i} \varphi(\hat{\bm{x}}) = 0\) for all \(i\in\{1,\dots,N\}\).
  Therefore,
  \begin{equation}
    L^{\lambda, N}\varphi (\hat{\bm{x}}) = \int_{\potspace^N} \underbrace{\br{\varphi(\bm{y}) - \varphi(\hat{\bm{x}})}}_{\leq 0} \lambda \kappa(\hat{\bm{x}}, \odif{\bm{y}})
    \leq 0.
  \end{equation}
\end{proof}

\bigskip

\begin{theorem}\label{thm:mart-problem-sol}
  Let \(\lambda > 0\), \(N \in \bN\), and let \(\nu \in \cP(\potspace^N)\) be an initial condition.
  Then the martingale problem for \((L^{\lambda, N}, \nu)\) has a solution. That means that there exists a a probability measure \(P^{\lambda, N} \in \cP(D_{\potspace^N}[0,T])\) such that for the stochastic process \(D_{\potspace^N}[0,T] \ni \omega \mapsto \bm{X}(t,\omega) \coloneqq \omega_t\) defined on \((D_{\potspace^N}[0,T], \cF \coloneqq \mathscr{S}_{\potspace^N}, P^{\lambda, N})\) and each \(\varphi \in D(L^{\lambda, N})\),
  \begin{equation}\label{eq:M-def}
    M_t^{\lambda, N}[\varphi]
    \coloneqq \varphi(\bm{X}_t) - \varphi(\bm{X}_0) - \int_0^t L^{\lambda, N} \varphi(\bm{X}_r) \odif{r}
  \end{equation}
  is a martingale w.r.t. the filtration \(\cF_t \coloneqq \cF_t^\bm{X}\).
\end{theorem}
\begin{proof}
  Because \(D(L^{\lambda, N}) = C^1(\potspace^N) \cap C_0(\potspace^N)\) is dense in \(C_0(\potspace^N)\) under the uniform norm, and \(L^{\lambda, N}\) satisfies the assumptions of Theorem 3.8 (EK), this follows from \zcref{lem:pos-max} combined with Theorem 5.4 (EK) and the remark below it.
\end{proof}

%%% Old text introducing the model (now in drift.tex etc.)
Let \(N \in \bN\) be the number of neurons.
Define the drift-generator \(L_D^{N} : C^1(\potspace^N) \cap C_0(\potspace^N) \to M_b(\potspace^N)\) as
% \begin{equation}
%     L^{\lambda, N}\varphi (\bm{x}) \coloneqq \sum_{i=1}^N b(x^i) \partial_{x^i} \varphi(\bm{x})
%     + \sum_{i=1}^N \int_\potspace \sbr{\varphi(x^1, \dots, x^{i-1}, y, x^{i+1}, \dots, x^N) - \varphi(\bm{x})} \lambda \kappa(x^i, \bm{x}, \odif{y})
% \end{equation}
\begin{equation}
  L_D^{N}\varphi \coloneqq \bm{b} \cdot \nabla_{\bm{x}} \varphi,
\end{equation}
where \(\bm{b} : \potspace^N \to \bR^N\) is defined as \(\bm{b}(\bm{x}) \coloneqq (b(x^1), \dots, b(x^N))^\top\), where \(b \in M_b(\potspace)\) is the physical driving force.
% but then multiplied with \(\1_{(-\infty,V_F)}\).
% We will assume that \(b\) satisfies the following linear growth assumption:
% \begin{equation}
%     \forall x \in \potspace : \abs{b(x)} \leq C (1 + \abs{x}),
% \end{equation}
% for some constant \(C > 0\).
Note that, in particular, \(b\) is locally bounded.
\newline
A typical example of such a driving force is the time-homogeneous \textit{leaky model}:
\begin{equation}
  b_{\mathrm{leaky}}(x) \coloneqq -(x - V_\mathrm{rest}),
\end{equation}
where \(V_\mathrm{rest} \in (V_R, V_F)\) is the equilibrium potential.



%%% Old stuff from long ago
\begin{equation}
  \mu^{\lambda, N} \coloneqq \frac{1}{N} \sum_{i=1}^N \delta_{X^i} \in \cP(\underbrace{D([0,T]; \potspace)}_{\eqqcolon \varGamma}),
  \quad \mu_t^{\lambda, N} \coloneqq (e_t)_\# \mu^{\lambda, N},
  \quad \varGamma \ni \omega \mapsto e_t(\omega) \coloneqq \omega_t.
\end{equation}
(Could see this as a push-forward of \(P^{\lambda, N} \to (\Theta_N)_\# P^{\lambda, N}\) where \(\Theta_N : \varGamma^N \to \cP(\varGamma); (\omega_1,\dots,\omega_N) \mapsto \frac{1}{N} \sum_{i=1}^N \delta_{\omega_i}\).)
Let \(P^{\lambda, N} \coloneqq \mathrm{Law}(\mu^{\lambda, N}) \in \cP(\cP(\varGamma))\).

\begin{lemma}
  If \(\potspace\) is compact, the collection \(\{P^{\lambda, N}\}_{\lambda,N}\) is tight.
\end{lemma}
\begin{proof}
  Because \(\potspace\) is compact, \(W_1\) metrizes the narrow topology on \(\cP(\varGamma)\).
  We have for all \(\omega \in \Omega\),
  \begin{equation}
    W_1(\mu^{\lambda, N}(\omega), \delta_0)
    = \int_{\varGamma} d_\varGamma(\gamma,0) \mu^{\lambda,N}(\omega) (\odif{\gamma})
    = \int_{\varGamma} \sup_{t \in [0,T]} \abs{\gamma_t} \mu^{\lambda,N}(\omega) (\odif{\gamma})
    = \frac{1}{N} \sum_{i=1}^N \sup_{t \in [0,T]} \abs{X^i_t(\omega)} \leq C,
  \end{equation}
  for some \(C > 0\).
  Hence
  \begin{equation}
    \sup_{\lambda, N} \int_\Omega W_1(\mu^{\lambda, N}(\omega), \delta_0) P^{\lambda, N}(\odif{\omega})
    = \Exp{}{W_1(\mu^{\lambda, N}, \delta_0)} < +\infty.
  \end{equation}
  By an OT exercise, this implies tightness.
\end{proof}



The martingale property is
\begin{equation}
  \Exp{}{M_t^{\lambda, N}[\varphi] - M_s^{\lambda, N}[\varphi] \given \cF_s} = 0
\end{equation}
for \(\cF_t \coloneqq \sigma(X_s : s \leq t)\).


I think we need, for Feller process:
\begin{itemize}
  \item A collection of probability measures \(\{P^\bm{Z}, \bm{Z} \in \bR^N\}\) on \((D_\bR([0,T])^N, \cF)\);

  \item A right-continuous filtration \(\{\cF_t, t \geq 0\}\) on \(D_\bR([0,T])^N\) with respect to which \(\bm{X}_t\) is adapted, and
        \begin{equation}
          P^\bm{Z}(\bm{X}(0) = \bm{Z}) = 1,
        \end{equation}
        the mapping \(x \mapsto E^\bm{Z} \varphi(\bm{X}_t)\) is in \(C_0(\bR^N)\) for all \(\varphi \in C_0(\bR^N)\) and \(t \geq 0\),
        and
        \begin{equation}
          E^\bm{Z}[ \bm{Y} \circ \theta_s \mid \cF_s] = E^{\bm{X}_s} \bm{Y} \quad \text{a.s. } P^\bm{Z}
        \end{equation}
        for all \(\bm{Z} \in \bR^N\) and all bounded measurable \(\bm{Y}\) on \(D_\bR([0,T])^N\). Here \((\theta_s\omega)_t = \omega{t+s}\).
\end{itemize}